{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#devito set up\n",
    "from abc import ABC, abstractmethod\n",
    "from devito import Operator, Function\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "from devito import Grid, Function, dimensions, Eq, Inc\n",
    "import sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_weights = torch.rand(2,3,3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: tensor([0.4423, 0.4008, 0.4268]) Var tensor([0.0629, 0.0745, 0.0931])\n"
     ]
    }
   ],
   "source": [
    "def batch_norm(weight):\n",
    "    eps = 1e-5\n",
    "    momentum = 0.1 #i dont know where it goes\n",
    "    Var = torch.var(weight, unbiased=False, axis = (0,2,3))\n",
    "    E = torch.mean(weight, axis = (0,2,3))\n",
    "    print(\"E:\", E, \"Var\",Var)\n",
    "    gamma = 1\n",
    "    betta = 0\n",
    "    result = torch.zeros_like(batch_weights)\n",
    "    for image in range(weight.shape[0]):\n",
    "        for channel in range(weight.shape[1]):\n",
    "            for x in range(weight.shape[2]):\n",
    "                for y in range(weight.shape[3]):\n",
    "                    result[image][channel][x][y]=(batch_weights[image][channel][x][y]-E[channel])\\\n",
    "                   /(np.sqrt(Var[channel]+1e-5))\n",
    "    return result\n",
    "py_res = batch_norm(batch_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.nn.BatchNorm2d(3, affine=False)\n",
    "torch_output = m(batch_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compare\n",
    "np.allclose(py_res, torch_output, atol = 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Devito implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loops to find the variance and the mean. Consider implementing them in devito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44230545, 0.40080094, 0.42683622])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the means\n",
    "images, channels, height, width = batch_weights.shape\n",
    "means = np.zeros(channels)\n",
    "#838 µs for 7 runs, 1000 loops each\n",
    "for channel in range(channels):\n",
    "    for image in range(images):\n",
    "        means[channel] += sum(sum(batch_weights[image][channel]))/(height*width)\n",
    "means/=images\n",
    "means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = torch.mean(batch_weights, axis = (0,2,3))\n",
    "E\n",
    "np.allclose(means, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06291315 0.07446667 0.09313467]\n",
      "is pytorch same as mine for Var? True\n"
     ]
    }
   ],
   "source": [
    "#find std\n",
    "var = np.zeros(channels)\n",
    "for channel in range(channels):\n",
    "    for image in range(images):\n",
    "            var[channel] += sum(sum(pow(batch_weights[image][channel]-means[channel],2)))/(height*width)\n",
    "var/=images\n",
    "print(var)\n",
    "Var = torch.var(batch_weights, unbiased=False, axis = (0,2,3))\n",
    "print(\"is pytorch same as mine for Var?\", np.allclose(Var, var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: tensor([0.4423, 0.4008, 0.4268]) Var tensor([0.0629, 0.0745, 0.0931])\n"
     ]
    }
   ],
   "source": [
    "#batchnorm only substract with means\n",
    "def batch_norm(weight):\n",
    "    eps = 1e-5\n",
    "    momentum = 0.1 #i dont know where it goes\n",
    "    Var = torch.var(weight, unbiased=False, axis = (0,2,3))\n",
    "    E = torch.mean(weight, axis = (0,2,3))\n",
    "    print(\"E:\", E, \"Var\",Var)\n",
    "    gamma = 1\n",
    "    betta = 0\n",
    "    result = torch.zeros_like(batch_weights)\n",
    "    for image in range(weight.shape[0]):\n",
    "        for channel in range(weight.shape[1]):\n",
    "            for x in range(weight.shape[2]):\n",
    "                for y in range(weight.shape[3]):\n",
    "                    result[image][channel][x][y]=(batch_weights[image][channel][x][y]-E[channel])\\\n",
    "                   /(np.sqrt(Var[channel]+1e-5))\n",
    "    return result\n",
    "py_res = batch_norm(batch_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#define _POSIX_C_SOURCE 200809L\n",
      "#include \"stdlib.h\"\n",
      "#include \"math.h\"\n",
      "#include \"sys/time.h\"\n",
      "#include \"xmmintrin.h\"\n",
      "#include \"pmmintrin.h\"\n",
      "#include \"omp.h\"\n",
      "\n",
      "struct dataobj\n",
      "{\n",
      "  void *restrict data;\n",
      "  int * size;\n",
      "  int * npsize;\n",
      "  int * dsize;\n",
      "  int * hsize;\n",
      "  int * hofs;\n",
      "  int * oofs;\n",
      "} ;\n",
      "\n",
      "struct profiler\n",
      "{\n",
      "  double section0;\n",
      "} ;\n",
      "\n",
      "\n",
      "int Kernel(struct dataobj *restrict B_vec, struct dataobj *restrict M_vec, struct dataobj *restrict R_vec, struct dataobj *restrict V_vec, const int a_M, const int a_m, const int b_M, const int b_m, const int c_M, const int c_m, const int d_M, const int d_m, struct profiler * timers, const int nthreads_nonaffine)\n",
      "{\n",
      "  float (*restrict B)[B_vec->size[1]][B_vec->size[2]][B_vec->size[3]] __attribute__ ((aligned (64))) = (float (*)[B_vec->size[1]][B_vec->size[2]][B_vec->size[3]]) B_vec->data;\n",
      "  float (*restrict M) __attribute__ ((aligned (64))) = (float (*)) M_vec->data;\n",
      "  float (*restrict R)[R_vec->size[1]][R_vec->size[2]][R_vec->size[3]] __attribute__ ((aligned (64))) = (float (*)[R_vec->size[1]][R_vec->size[2]][R_vec->size[3]]) R_vec->data;\n",
      "  float (*restrict V) __attribute__ ((aligned (64))) = (float (*)) V_vec->data;\n",
      "\n",
      "  /* Flush denormal numbers to zero in hardware */\n",
      "  _MM_SET_DENORMALS_ZERO_MODE(_MM_DENORMALS_ZERO_ON);\n",
      "  _MM_SET_FLUSH_ZERO_MODE(_MM_FLUSH_ZERO_ON);\n",
      "  struct timeval start_section0, end_section0;\n",
      "  gettimeofday(&start_section0, NULL);\n",
      "  /* Begin section0 */\n",
      "  #pragma omp parallel num_threads(nthreads_nonaffine)\n",
      "  {\n",
      "    int chunk_size = (int)(fmax(1, (1.0F/3.0F)*(a_M - a_m + 1)/nthreads_nonaffine));\n",
      "    #pragma omp for collapse(1) schedule(dynamic,chunk_size)\n",
      "    for (int a = a_m; a <= a_M; a += 1)\n",
      "    {\n",
      "      for (int b = b_m; b <= b_M; b += 1)\n",
      "      {\n",
      "        for (int c = c_m; c <= c_M; c += 1)\n",
      "        {\n",
      "          #pragma omp simd aligned(B,M,R,V:32)\n",
      "          for (int d = d_m; d <= d_M; d += 1)\n",
      "          {\n",
      "            R[a][b][c][d] = (-M[b] + B[a][b][c][d])*pow(V[b] + 1.0e-5F, -5.0e-1F);\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  /* End section0 */\n",
      "  gettimeofday(&end_section0, NULL);\n",
      "  timers->section0 += (double)(end_section0.tv_sec-start_section0.tv_sec)+(double)(end_section0.tv_usec-start_section0.tv_usec)/1000000;\n",
      "  return 0;\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#devito\n",
    "a, b, c, d = dimensions('a b c d')\n",
    "gridB = Grid(shape=(2,3,3,3), dimensions = (a, b, c, d) )\n",
    "B = Function(name='B', grid=gridB, space_order=0)\n",
    "\n",
    "B.data[:] = batch_weights[:]\n",
    "\n",
    "e, f, g, h = dimensions('e f g h')\n",
    "gridR = Grid(shape=(2,3,3,3), dimensions = (e, f, g, h) )\n",
    "R = Function(name='R', grid=gridR, space_order=0)\n",
    "\n",
    "R.data[:] = 0\n",
    "\n",
    "images, channels, height, width = batch_weights.shape\n",
    "gridMean = Grid(shape=(channels))\n",
    "M = Function(name= 'M', grid=gridMean,space_order=0)\n",
    "#find the means\n",
    "\n",
    "means = np.zeros(channels)\n",
    "#838 µs for 7 runs, 1000 loops each\n",
    "for channel in range(channels):\n",
    "    for image in range(images):\n",
    "        means[channel] += sum(sum(batch_weights[image][channel]))/(height*width)\n",
    "means/=images\n",
    "means\n",
    "M.data[:]=means[:]\n",
    "# var\n",
    "gridVar = Grid(shape=(channels))\n",
    "V = Function(name= 'V', grid=gridVar,space_order=0)\n",
    "#find var\n",
    "\n",
    "var = np.zeros(channels)\n",
    "for channel in range(channels):\n",
    "    for image in range(images):\n",
    "            var[channel] += sum(sum(pow(batch_weights[image][channel]-means[channel],2)))/(height*width)\n",
    "            \n",
    "var/=images\n",
    "\n",
    "#var = torch.var(batch_weights, axis = (0,2,3))\n",
    "V.data[:] = var[:]\n",
    "\n",
    "epsilon = 1e-5\n",
    "\n",
    "#rhs = B[a,b,c,d]-M[b]\n",
    "rhs = ((B[a,b,c,d]-M[b])/(((V[b]+epsilon)**(0.5))))\n",
    "\n",
    "op = Operator(Eq(R[a, b, c, d], rhs))\n",
    "op\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Operator `Kernel` run in 0.01 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 1.1921e-07,  1.1921e-07,  2.3842e-07],\n",
       "          [ 1.0803e-07,  1.1921e-07,  5.9605e-08],\n",
       "          [ 0.0000e+00,  1.1921e-07,  5.9605e-08]],\n",
       "\n",
       "         [[ 1.1921e-07,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.0431e-07,  5.9605e-08,  1.1921e-07],\n",
       "          [ 1.1921e-07,  1.1921e-07,  5.9605e-08]]],\n",
       "\n",
       "\n",
       "        [[[-1.1921e-07,  0.0000e+00,  0.0000e+00],\n",
       "          [-5.9605e-08, -3.7253e-09,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 1.1921e-07,  1.1921e-07,  1.1921e-07],\n",
       "          [ 1.1921e-07,  1.1921e-07,  1.1921e-07],\n",
       "          [ 1.1921e-07,  1.1921e-07,  1.1921e-07]],\n",
       "\n",
       "         [[ 5.9605e-08,  1.1921e-07,  9.4995e-08],\n",
       "          [ 8.9407e-08,  5.9605e-08,  1.1921e-07],\n",
       "          [ 1.1921e-07,  1.1921e-07,  1.1921e-07]]]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = op.apply()\n",
    "print(np.allclose(py_res, R.data))\n",
    "py_res - R.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.7517,  0.3583,  1.8362],\n",
       "          [ 0.3391,  0.1500, -0.2117],\n",
       "          [ 1.4750,  0.1713, -1.2843]],\n",
       "\n",
       "         [[-1.1523, -1.2914,  2.1674],\n",
       "          [-0.0621,  0.7287, -0.5442],\n",
       "          [-1.2156,  1.4488, -0.6526]],\n",
       "\n",
       "         [[-0.5391, -1.2252, -1.2412],\n",
       "          [ 0.1044, -0.9599,  1.3165],\n",
       "          [ 1.8083,  0.5404, -0.5330]]],\n",
       "\n",
       "\n",
       "        [[[-1.7561, -0.6529,  0.6240],\n",
       "          [-0.5909, -0.0582, -0.1333],\n",
       "          [-1.1424,  0.4085, -1.2845]],\n",
       "\n",
       "         [[ 0.1454, -1.0434, -0.5916],\n",
       "          [ 0.6986, -0.6055,  0.3117],\n",
       "          [ 0.2491, -0.2967,  1.7057]],\n",
       "\n",
       "         [[-0.6627,  1.6172, -0.0307],\n",
       "          [-0.4549, -0.9277,  0.7403],\n",
       "          [-1.3396,  0.6794,  1.1076]]]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.8817, 0.5322, 0.9029],\n",
       "          [0.5274, 0.4799, 0.3892],\n",
       "          [0.8123, 0.4853, 0.1202]],\n",
       "\n",
       "         [[0.0863, 0.0484, 0.9923],\n",
       "          [0.3839, 0.5997, 0.2523],\n",
       "          [0.0691, 0.7962, 0.2227]],\n",
       "\n",
       "         [[0.2623, 0.0529, 0.0480],\n",
       "          [0.4587, 0.1339, 0.8286],\n",
       "          [0.9787, 0.5918, 0.2642]]],\n",
       "\n",
       "\n",
       "        [[[0.0018, 0.2785, 0.5988],\n",
       "          [0.2941, 0.4277, 0.4089],\n",
       "          [0.1557, 0.5448, 0.1201]],\n",
       "\n",
       "         [[0.4405, 0.1160, 0.2394],\n",
       "          [0.5915, 0.2356, 0.4859],\n",
       "          [0.4688, 0.3198, 0.8663]],\n",
       "\n",
       "         [[0.2246, 0.9204, 0.4175],\n",
       "          [0.2880, 0.1437, 0.6528],\n",
       "          [0.0180, 0.6342, 0.7649]]]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.3123,  0.2684,  1.3756],\n",
       "          [ 0.2541,  0.1124, -0.1586],\n",
       "          [ 1.1050,  0.1284, -0.9621]],\n",
       "\n",
       "         [[-0.8378, -0.9389,  1.5759],\n",
       "          [-0.0451,  0.5298, -0.3957],\n",
       "          [-0.8838,  1.0534, -0.4745]],\n",
       "\n",
       "         [[-0.3746, -0.8513, -0.8624],\n",
       "          [ 0.0726, -0.6670,  0.9147],\n",
       "          [ 1.2564,  0.3755, -0.3703]]],\n",
       "\n",
       "\n",
       "        [[[-1.3156, -0.4891,  0.4675],\n",
       "          [-0.4426, -0.0436, -0.0999],\n",
       "          [-0.8559,  0.3060, -0.9623]],\n",
       "\n",
       "         [[ 0.1057, -0.7587, -0.4301],\n",
       "          [ 0.5080, -0.4402,  0.2266],\n",
       "          [ 0.1811, -0.2157,  1.2402]],\n",
       "\n",
       "         [[-0.4604,  1.1236, -0.0213],\n",
       "          [-0.3161, -0.6446,  0.5144],\n",
       "          [-0.9308,  0.4721,  0.7696]]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_output - R.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data([[[[0.8817157 , 0.53217876, 0.90290296],\n",
       "        [0.52737516, 0.47992754, 0.38920242],\n",
       "        [0.8123122 , 0.4852845 , 0.12015229]],\n",
       "\n",
       "       [[0.08633733, 0.04838318, 0.9923008 ],\n",
       "        [0.38385695, 0.59966034, 0.2522865 ],\n",
       "        [0.06906962, 0.7961829 , 0.22271138]],\n",
       "\n",
       "       [[0.2622897 , 0.05289882, 0.04802912],\n",
       "        [0.45870745, 0.13387042, 0.82863754],\n",
       "        [0.9787218 , 0.59176695, 0.2641641 ]]],\n",
       "\n",
       "\n",
       "      [[[0.00179935, 0.2785223 , 0.5988449 ],\n",
       "        [0.29409194, 0.42771864, 0.40886676],\n",
       "        [0.15573186, 0.5447799 , 0.1200909 ]],\n",
       "\n",
       "       [[0.4404782 , 0.11603916, 0.23935169],\n",
       "        [0.5914536 , 0.23556674, 0.48585397],\n",
       "        [0.46877456, 0.31982666, 0.8662832 ]],\n",
       "\n",
       "       [[0.22459686, 0.9203958 , 0.4174602 ],\n",
       "        [0.28800595, 0.14369202, 0.6527707 ],\n",
       "        [0.0179913 , 0.6341867 , 0.7648663 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
