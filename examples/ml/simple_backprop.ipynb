{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple backpropagation in Devito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we'll implement a simple convolutional neural network (CNN) in Devito, run a forward pass through it and then use backpropagation to obtain gradients necessary for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CNN will have the following structure:\n",
    "1. Max pool layer: input size 1x2x4x4, kernel size 2x2, stride 1x1\n",
    "2. Convolutional layer: input size 1x2x3x3, kernel size 2x2x2, stride 1x1, activation ReLU\n",
    "3. Flattening layer\n",
    "4. Fully connected layer: input size 8x1, kernel size 3x8, activation softmax\n",
    "\n",
    "*Size glossary: batch size x channels x height x width **or** output channels x height x width **or** height x width. Height and width are equivalent to rows and columns.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All parameters for the forward pass will be (pseudo)random numbers generated by `np.random.rand`. Therefore, different results will be obtained each time the notebook is executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import devito.ml\n",
    "import numpy as np\n",
    "from sympy import Max\n",
    "from sympy.functions import sign\n",
    "from devito import Operator, Eq, Inc\n",
    "from devito.ml.loss import cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass(conv_kernel, conv_bias, fc_weights, fc_bias, input_data, expected_results):\n",
    "    layer1 = devito.ml.Subsampling(kernel_size=(2, 2),\n",
    "                                   input_size=(1, 2, 4, 4),\n",
    "                                   function=lambda l: Max(*l),\n",
    "                                   generate_code=False)\n",
    "    layer2 = devito.ml.Conv(kernel_size=(2, 2, 2),\n",
    "                            input_size=(1, 2, 3, 3),\n",
    "                            activation=lambda x: Max(0, x),\n",
    "                            generate_code=False)\n",
    "    layer_flat = devito.ml.Flat(input_size=(1, 2, 2, 2),\n",
    "                                generate_code=False)\n",
    "    layer3 = devito.ml.FullyConnectedSoftmax(weight_size=(3, 8),\n",
    "                                             input_size=(8, 1),\n",
    "                                             generate_code=False)\n",
    "    \n",
    "    eqs = layer1.equations() + layer2.equations(layer1.result) + \\\n",
    "            layer_flat.equations(layer2.result) + layer3.equations(layer_flat.result)\n",
    "    \n",
    "    op = Operator(eqs)\n",
    "    \n",
    "    layer2.kernel.data[:] = conv_kernel\n",
    "    layer2.bias.data[:] = conv_bias\n",
    "    \n",
    "    layer3.kernel.data[:] = fc_weights\n",
    "    layer3.bias.data[:] = fc_bias\n",
    "    \n",
    "    layer1.input.data[:] = input_data\n",
    "    \n",
    "    op.apply()\n",
    "    \n",
    "    gradients = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        result = layer3.result.data[i]\n",
    "        if i == expected_results[0]:\n",
    "            result -= 1\n",
    "        gradients.append(result)\n",
    "    \n",
    "    layer3.result_gradients.data[:] = gradients\n",
    "    \n",
    "    dims = [layer3.bias_gradients.dimensions[0],\n",
    "            layer3.kernel_gradients.dimensions[0],\n",
    "            layer3.kernel_gradients.dimensions[1],\n",
    "            layer_flat.result_gradients.dimensions[0],\n",
    "            layer3.kernel.dimensions[1],\n",
    "            layer3.result_gradients.dimensions[0],\n",
    "            layer2.result_gradients.dimensions[0],\n",
    "            layer2.result_gradients.dimensions[1],\n",
    "            layer2.result_gradients.dimensions[2],\n",
    "            layer2.kernel_gradients.dimensions[0],\n",
    "            layer2.kernel_gradients.dimensions[1],\n",
    "            layer2.kernel_gradients.dimensions[2],\n",
    "            layer2.kernel_gradients.dimensions[3],\n",
    "            layer2.bias_gradients.dimensions[0]]\n",
    "    \n",
    "    _, _, layer2_height, layer2_width = layer2.kernel.shape\n",
    "    \n",
    "    backprop_eqs = [\n",
    "        Eq(layer3.bias_gradients[dims[0]], layer3.result_gradients[dims[0]]),\n",
    "        Eq(layer3.kernel_gradients[dims[1], dims[2]],\n",
    "           layer_flat.result[dims[2], 0] * layer3.result_gradients[dims[1]]),\n",
    "        Inc(layer_flat.result_gradients[dims[4]],\n",
    "            layer3.kernel[dims[5], dims[4]] * layer3.result_gradients[dims[5]]),\n",
    "        Eq(layer_flat.result_gradients[dims[3]],\n",
    "           layer_flat.result_gradients[dims[3]] * sign(layer_flat.result[dims[3], 0])),\n",
    "        Eq(layer2.result_gradients[dims[6], dims[7], dims[8]],\n",
    "           layer_flat.result_gradients[dims[6] * layer2_height * layer2_width + dims[7] * layer2_height + dims[8]]),\n",
    "        Inc(layer2.bias_gradients[dims[13]], layer2.result_gradients[dims[13], dims[7], dims[8]]),\n",
    "        Eq(layer2.kernel_gradients[dims[9], dims[10], dims[11], dims[12]],\n",
    "            sum([layer2.result_gradients[dims[9], x, y] * layer1.result[0, dims[10], dims[11] + x, dims[12] + y]\n",
    "                 for x in range(layer2.result_gradients.shape[1])\n",
    "                 for y in range(layer2.result_gradients.shape[2])]))\n",
    "    ]\n",
    "    \n",
    "    backprop_op = Operator(backprop_eqs)\n",
    "    backprop_op.apply()\n",
    "    \n",
    "    return (layer2.kernel_gradients.data, layer2.bias_gradients.data,\n",
    "            layer3.kernel_gradients.data, layer3.bias_gradients.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_kernel = np.random.rand(2, 2, 2)\n",
    "conv_bias = np.random.rand(2)\n",
    "\n",
    "fc_weights = np.random.rand(3, 8)\n",
    "fc_bias = np.random.rand(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.array([[[[1, 2, 3, 4],\n",
    "                         [5, 6, 7, 8],\n",
    "                         [9, 10, 11, 12],\n",
    "                         [13, 14, 15, 16]],\n",
    "                        [[-1, -2, 0, 1],\n",
    "                         [-2, -3, 1, 2],\n",
    "                         [3, 4, 2, -1],\n",
    "                         [-2, -3, -4, 9]]]],\n",
    "                     dtype=np.float32)\n",
    "expected = np.array([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maksymilian/Desktop/UROP/devito/devito/types/grid.py:206: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  spacing = (np.array(self.extent) / (np.array(self.shape) - 1)).astype(self.dtype)\n",
      "Operator `Kernel` run in 0.01 s\n",
      "Operator `Kernel` run in 0.01 s\n"
     ]
    }
   ],
   "source": [
    "conv_kernel_grad, conv_bias_grad, fc_kernel_grad, fc_bias_grad = backward_pass(conv_kernel, conv_bias, fc_weights, fc_bias, input_data, expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are kernel gradients of the convolutional layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 2.52394244  2.48879787]\n",
      "   [ 2.38336418  2.34821962]]\n",
      "\n",
      "  [[ 2.80713868  0.41273551]\n",
      "   [-0.14057825  2.57469963]]]\n",
      "\n",
      "\n",
      " [[[ 4.78655447  5.42670352]\n",
      "   [ 7.34715068  7.98729973]]\n",
      "\n",
      "  [[ 0.95639079  1.29162432]\n",
      "   [ 2.56059621  1.5953034 ]]]]\n"
     ]
    }
   ],
   "source": [
    "print(conv_kernel_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are bias gradients of the convolutional layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03514456  0.64014905]\n"
     ]
    }
   ],
   "source": [
    "print(conv_bias_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are kernel gradients of the fully connected layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.67242849e+01  3.03500473e+01  4.22950883e+01  4.70518591e+01\n",
      "   2.64219242e+01  3.00476867e+01  4.19927277e+01  4.67494985e+01]\n",
      " [ 2.52522893e-07  2.86783418e-07  3.99654401e-07  4.44602041e-07\n",
      "   2.49665829e-07  2.83926354e-07  3.96797337e-07  4.41744977e-07]\n",
      " [-2.67242852e+01 -3.03500476e+01 -4.22950887e+01 -4.70518596e+01\n",
      "  -2.64219245e+01 -3.00476870e+01 -4.19927281e+01 -4.67494989e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(fc_kernel_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are bias gradients of the fully connected layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.99999991e-01  9.44919169e-09 -1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(fc_bias_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with PyTorch\n",
    "To check correctness, we will carry out the same activities using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Conv2d(2, 2, 2)\n",
    "        self.fc = nn.Linear(8, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(x, 2, stride=(1, 1))\n",
    "        x = F.relu(self.conv(x))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "\n",
    "with torch.no_grad():\n",
    "    net.conv.weight[:] = torch.from_numpy(conv_kernel)\n",
    "    net.conv.bias[:] = torch.from_numpy(conv_bias)\n",
    "    \n",
    "    net.fc.weight[:] = torch.from_numpy(fc_weights)\n",
    "    net.fc.bias[:] = torch.from_numpy(fc_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "input_data_tensor = torch.from_numpy(input_data)\n",
    "outputs = net(input_data_tensor)\n",
    "net.zero_grad()\n",
    "loss = criterion(outputs, torch.from_numpy(expected))\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the relative convolutional layer kernel error along with the maximum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[2.01877140e-07 3.94801855e-07]\n",
      "   [3.07473025e-07 3.10464598e-07]]\n",
      "\n",
      "  [[8.58674692e-08 3.13463644e-07]\n",
      "   [3.28439227e-06 1.90526279e-07]]]\n",
      "\n",
      "\n",
      " [[[2.82935917e-08 1.30557783e-08]\n",
      "   [4.81751494e-08 2.34705184e-08]]\n",
      "\n",
      "  [[1.18480278e-07 1.01032443e-07]\n",
      "   [7.77058406e-09 6.25597436e-08]]]]\n",
      "3.284392272922269e-06\n"
     ]
    }
   ],
   "source": [
    "pytorch_conv_kernel_grad = net.conv.weight.grad.numpy()\n",
    "conv_kernel_error = abs(conv_kernel_grad - pytorch_conv_kernel_grad) / abs(pytorch_conv_kernel_grad)\n",
    "print(conv_kernel_error)\n",
    "print(np.amax(conv_kernel_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the relative convolutional layer bias error along with the maximum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.28439227e-06 7.77058389e-09]\n",
      "3.284392272922269e-06\n"
     ]
    }
   ],
   "source": [
    "pytorch_conv_bias_grad = net.conv.bias.grad.numpy()\n",
    "conv_bias_error = abs(conv_bias_grad - pytorch_conv_bias_grad) / abs(pytorch_conv_bias_grad)\n",
    "print(conv_bias_error)\n",
    "print(np.amax(conv_bias_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the relative fully connected layer kernel error along with the maximum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.18678810e-09 2.36218444e-08 3.30552477e-08 3.54522337e-08\n",
      "  1.33973518e-08 2.83589833e-08 3.65128070e-08 3.85734888e-08]\n",
      " [4.10119855e-06 4.01238638e-06 3.99316853e-06 4.00372797e-06\n",
      "  4.03413996e-06 4.05262906e-06 4.02182561e-06 4.02953748e-06]\n",
      " [1.26240327e-09 1.41726531e-08 2.36060563e-08 2.60030427e-08\n",
      "  3.94816045e-09 1.89097921e-08 2.70636159e-08 2.91242978e-08]]\n",
      "4.101198550901649e-06\n"
     ]
    }
   ],
   "source": [
    "pytorch_fc_kernel_grad = net.fc.weight.grad.numpy()\n",
    "fc_kernel_error = abs(fc_kernel_grad - pytorch_fc_kernel_grad) / abs(pytorch_fc_kernel_grad)\n",
    "print(fc_kernel_error)\n",
    "print(np.amax(fc_kernel_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the relative fully connected layer bias error along with the maximum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.44926493e-09 4.04605208e-06 7.34967642e-14]\n",
      "4.046052084759483e-06\n"
     ]
    }
   ],
   "source": [
    "pytorch_fc_bias_grad = net.fc.bias.grad.numpy()\n",
    "fc_bias_error = abs(fc_bias_grad - pytorch_fc_bias_grad) / abs(pytorch_fc_bias_grad)\n",
    "print(fc_bias_error)\n",
    "print(np.amax(fc_bias_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the maximum overall error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.101198550901649e-06\n"
     ]
    }
   ],
   "source": [
    "print(max(np.amax(conv_kernel_error), np.amax(conv_bias_error), np.amax(fc_kernel_error), np.amax(fc_bias_error)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
